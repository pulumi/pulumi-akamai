# coding=utf-8
# *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import warnings
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
from . import _utilities
from . import outputs
from ._inputs import *

__all__ = ['DatastreamArgs', 'Datastream']

@pulumi.input_type
class DatastreamArgs:
    def __init__(__self__, *,
                 active: pulumi.Input[bool],
                 config: pulumi.Input['DatastreamConfigArgs'],
                 contract_id: pulumi.Input[str],
                 dataset_fields_ids: pulumi.Input[Sequence[pulumi.Input[int]]],
                 group_id: pulumi.Input[str],
                 property_ids: pulumi.Input[Sequence[pulumi.Input[str]]],
                 stream_name: pulumi.Input[str],
                 stream_type: pulumi.Input[str],
                 template_name: pulumi.Input[str],
                 azure_connector: Optional[pulumi.Input['DatastreamAzureConnectorArgs']] = None,
                 datadog_connector: Optional[pulumi.Input['DatastreamDatadogConnectorArgs']] = None,
                 email_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 gcs_connector: Optional[pulumi.Input['DatastreamGcsConnectorArgs']] = None,
                 https_connector: Optional[pulumi.Input['DatastreamHttpsConnectorArgs']] = None,
                 oracle_connector: Optional[pulumi.Input['DatastreamOracleConnectorArgs']] = None,
                 s3_connector: Optional[pulumi.Input['DatastreamS3ConnectorArgs']] = None,
                 splunk_connector: Optional[pulumi.Input['DatastreamSplunkConnectorArgs']] = None,
                 sumologic_connector: Optional[pulumi.Input['DatastreamSumologicConnectorArgs']] = None):
        """
        The set of arguments for constructing a Datastream resource.
        :param pulumi.Input[bool] active: - (Required) Whether you want to start activating the stream when applying the resource. Either `true` for activating the stream upon sending the request or `false` for leaving the stream inactive after the request.
        :param pulumi.Input['DatastreamConfigArgs'] config: - (Required) Provides information about the log line configuration, log file format, names of log files sent, and file delivery. The argument includes these sub-arguments:
        :param pulumi.Input[str] contract_id: - (Required) Identifies the contract that has access to the product.
        :param pulumi.Input[Sequence[pulumi.Input[int]]] dataset_fields_ids: - (Required)	Identifiers of the data set fields within the template that you want to receive in logs. The order of the identifiers define how the value for these fields appears in the log lines. See [Data set parameters](https://techdocs.akamai.com/datastream2/reference/data-set-parameters-1).
        :param pulumi.Input[str] group_id: - (Required) Identifies the group that has access to the product and this stream configuration.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] property_ids: - (Required) Identifies the properties that you want to monitor in the stream. Note that a stream can only log data for active properties.
        :param pulumi.Input[str] stream_name: - (Required) The name of the stream.
        :param pulumi.Input[str] stream_type: - (Required) The type of stream that you want to create. Currently, `RAW_LOGS` is the only possible stream type.
        :param pulumi.Input[str] template_name: - (Required) The name of the data set template available for the product that you want to use in the stream. Currently, `EDGE_LOGS` is the only data set template available.
        :param pulumi.Input['DatastreamAzureConnectorArgs'] azure_connector: Specify details about the Azure Storage connector configuration in a data stream. Note that currently DataStream supports only streaming data to [block objects](https://docs.microsoft.com/en-us/rest/api/storageservices/understanding-block-blobs--append-blobs--and-page-blobs). The argument includes these sub-arguments:
        :param pulumi.Input['DatastreamDatadogConnectorArgs'] datadog_connector: Specify details about the Datadog connector in a stream, including:
        :param pulumi.Input[Sequence[pulumi.Input[str]]] email_ids: - (Optional) A list of email addresses you want to notify about activations and deactivations of the stream.
        :param pulumi.Input['DatastreamGcsConnectorArgs'] gcs_connector: Specify details about the Google Cloud Storage connector you can use in a stream. When validating this connector, DataStream uses the private access key to create an `Akamai_access_verification_<timestamp>.txt` object file in your GCS bucket. You can only see this file if the validation process is successful, and you have access to the Google Cloud Storage bucket where you are trying to send logs. The argument includes these sub-arguments:
        :param pulumi.Input['DatastreamHttpsConnectorArgs'] https_connector: Specify details about the custom HTTPS endpoint you can use as a connector for a stream, including:
        :param pulumi.Input['DatastreamOracleConnectorArgs'] oracle_connector: Specify details about the Oracle Cloud Storage connector in a stream. When validating this connector, DataStream uses the provided `access_key` and `secret_access_key` values and tries to save an `Akamai_access_verification_<timestamp>.txt` file in your Oracle Cloud Storage folder. You can only see this file if the validation process is successful, and you have access to the Oracle Cloud Storage bucket and folder that you’re trying to send logs to.
        :param pulumi.Input['DatastreamS3ConnectorArgs'] s3_connector: - (Optional) Specify details about the Amazon S3 connector in a stream. When validating this connector, DataStream uses the provided `access_key` and `secret_access_key` values and saves an `akamai_write_test_2147483647.txt` file in your Amazon S3 folder. You can only see this file if validation succeeds, and you have access to the Amazon S3 bucket and folder that you’re trying to send logs to. The argument includes these sub-arguments:
        :param pulumi.Input['DatastreamSplunkConnectorArgs'] splunk_connector: Specify details about the Splunk connector in your stream. Note that currently DataStream supports only endpoint URLs ending with `collector/raw`. The argument includes these sub-arguments:
        :param pulumi.Input['DatastreamSumologicConnectorArgs'] sumologic_connector: Specify details about the Sumo Logic connector in a stream, including:
        """
        pulumi.set(__self__, "active", active)
        pulumi.set(__self__, "config", config)
        pulumi.set(__self__, "contract_id", contract_id)
        pulumi.set(__self__, "dataset_fields_ids", dataset_fields_ids)
        pulumi.set(__self__, "group_id", group_id)
        pulumi.set(__self__, "property_ids", property_ids)
        pulumi.set(__self__, "stream_name", stream_name)
        pulumi.set(__self__, "stream_type", stream_type)
        pulumi.set(__self__, "template_name", template_name)
        if azure_connector is not None:
            pulumi.set(__self__, "azure_connector", azure_connector)
        if datadog_connector is not None:
            pulumi.set(__self__, "datadog_connector", datadog_connector)
        if email_ids is not None:
            pulumi.set(__self__, "email_ids", email_ids)
        if gcs_connector is not None:
            pulumi.set(__self__, "gcs_connector", gcs_connector)
        if https_connector is not None:
            pulumi.set(__self__, "https_connector", https_connector)
        if oracle_connector is not None:
            pulumi.set(__self__, "oracle_connector", oracle_connector)
        if s3_connector is not None:
            pulumi.set(__self__, "s3_connector", s3_connector)
        if splunk_connector is not None:
            pulumi.set(__self__, "splunk_connector", splunk_connector)
        if sumologic_connector is not None:
            pulumi.set(__self__, "sumologic_connector", sumologic_connector)

    @property
    @pulumi.getter
    def active(self) -> pulumi.Input[bool]:
        """
        - (Required) Whether you want to start activating the stream when applying the resource. Either `true` for activating the stream upon sending the request or `false` for leaving the stream inactive after the request.
        """
        return pulumi.get(self, "active")

    @active.setter
    def active(self, value: pulumi.Input[bool]):
        pulumi.set(self, "active", value)

    @property
    @pulumi.getter
    def config(self) -> pulumi.Input['DatastreamConfigArgs']:
        """
        - (Required) Provides information about the log line configuration, log file format, names of log files sent, and file delivery. The argument includes these sub-arguments:
        """
        return pulumi.get(self, "config")

    @config.setter
    def config(self, value: pulumi.Input['DatastreamConfigArgs']):
        pulumi.set(self, "config", value)

    @property
    @pulumi.getter(name="contractId")
    def contract_id(self) -> pulumi.Input[str]:
        """
        - (Required) Identifies the contract that has access to the product.
        """
        return pulumi.get(self, "contract_id")

    @contract_id.setter
    def contract_id(self, value: pulumi.Input[str]):
        pulumi.set(self, "contract_id", value)

    @property
    @pulumi.getter(name="datasetFieldsIds")
    def dataset_fields_ids(self) -> pulumi.Input[Sequence[pulumi.Input[int]]]:
        """
        - (Required)	Identifiers of the data set fields within the template that you want to receive in logs. The order of the identifiers define how the value for these fields appears in the log lines. See [Data set parameters](https://techdocs.akamai.com/datastream2/reference/data-set-parameters-1).
        """
        return pulumi.get(self, "dataset_fields_ids")

    @dataset_fields_ids.setter
    def dataset_fields_ids(self, value: pulumi.Input[Sequence[pulumi.Input[int]]]):
        pulumi.set(self, "dataset_fields_ids", value)

    @property
    @pulumi.getter(name="groupId")
    def group_id(self) -> pulumi.Input[str]:
        """
        - (Required) Identifies the group that has access to the product and this stream configuration.
        """
        return pulumi.get(self, "group_id")

    @group_id.setter
    def group_id(self, value: pulumi.Input[str]):
        pulumi.set(self, "group_id", value)

    @property
    @pulumi.getter(name="propertyIds")
    def property_ids(self) -> pulumi.Input[Sequence[pulumi.Input[str]]]:
        """
        - (Required) Identifies the properties that you want to monitor in the stream. Note that a stream can only log data for active properties.
        """
        return pulumi.get(self, "property_ids")

    @property_ids.setter
    def property_ids(self, value: pulumi.Input[Sequence[pulumi.Input[str]]]):
        pulumi.set(self, "property_ids", value)

    @property
    @pulumi.getter(name="streamName")
    def stream_name(self) -> pulumi.Input[str]:
        """
        - (Required) The name of the stream.
        """
        return pulumi.get(self, "stream_name")

    @stream_name.setter
    def stream_name(self, value: pulumi.Input[str]):
        pulumi.set(self, "stream_name", value)

    @property
    @pulumi.getter(name="streamType")
    def stream_type(self) -> pulumi.Input[str]:
        """
        - (Required) The type of stream that you want to create. Currently, `RAW_LOGS` is the only possible stream type.
        """
        return pulumi.get(self, "stream_type")

    @stream_type.setter
    def stream_type(self, value: pulumi.Input[str]):
        pulumi.set(self, "stream_type", value)

    @property
    @pulumi.getter(name="templateName")
    def template_name(self) -> pulumi.Input[str]:
        """
        - (Required) The name of the data set template available for the product that you want to use in the stream. Currently, `EDGE_LOGS` is the only data set template available.
        """
        return pulumi.get(self, "template_name")

    @template_name.setter
    def template_name(self, value: pulumi.Input[str]):
        pulumi.set(self, "template_name", value)

    @property
    @pulumi.getter(name="azureConnector")
    def azure_connector(self) -> Optional[pulumi.Input['DatastreamAzureConnectorArgs']]:
        """
        Specify details about the Azure Storage connector configuration in a data stream. Note that currently DataStream supports only streaming data to [block objects](https://docs.microsoft.com/en-us/rest/api/storageservices/understanding-block-blobs--append-blobs--and-page-blobs). The argument includes these sub-arguments:
        """
        return pulumi.get(self, "azure_connector")

    @azure_connector.setter
    def azure_connector(self, value: Optional[pulumi.Input['DatastreamAzureConnectorArgs']]):
        pulumi.set(self, "azure_connector", value)

    @property
    @pulumi.getter(name="datadogConnector")
    def datadog_connector(self) -> Optional[pulumi.Input['DatastreamDatadogConnectorArgs']]:
        """
        Specify details about the Datadog connector in a stream, including:
        """
        return pulumi.get(self, "datadog_connector")

    @datadog_connector.setter
    def datadog_connector(self, value: Optional[pulumi.Input['DatastreamDatadogConnectorArgs']]):
        pulumi.set(self, "datadog_connector", value)

    @property
    @pulumi.getter(name="emailIds")
    def email_ids(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        - (Optional) A list of email addresses you want to notify about activations and deactivations of the stream.
        """
        return pulumi.get(self, "email_ids")

    @email_ids.setter
    def email_ids(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "email_ids", value)

    @property
    @pulumi.getter(name="gcsConnector")
    def gcs_connector(self) -> Optional[pulumi.Input['DatastreamGcsConnectorArgs']]:
        """
        Specify details about the Google Cloud Storage connector you can use in a stream. When validating this connector, DataStream uses the private access key to create an `Akamai_access_verification_<timestamp>.txt` object file in your GCS bucket. You can only see this file if the validation process is successful, and you have access to the Google Cloud Storage bucket where you are trying to send logs. The argument includes these sub-arguments:
        """
        return pulumi.get(self, "gcs_connector")

    @gcs_connector.setter
    def gcs_connector(self, value: Optional[pulumi.Input['DatastreamGcsConnectorArgs']]):
        pulumi.set(self, "gcs_connector", value)

    @property
    @pulumi.getter(name="httpsConnector")
    def https_connector(self) -> Optional[pulumi.Input['DatastreamHttpsConnectorArgs']]:
        """
        Specify details about the custom HTTPS endpoint you can use as a connector for a stream, including:
        """
        return pulumi.get(self, "https_connector")

    @https_connector.setter
    def https_connector(self, value: Optional[pulumi.Input['DatastreamHttpsConnectorArgs']]):
        pulumi.set(self, "https_connector", value)

    @property
    @pulumi.getter(name="oracleConnector")
    def oracle_connector(self) -> Optional[pulumi.Input['DatastreamOracleConnectorArgs']]:
        """
        Specify details about the Oracle Cloud Storage connector in a stream. When validating this connector, DataStream uses the provided `access_key` and `secret_access_key` values and tries to save an `Akamai_access_verification_<timestamp>.txt` file in your Oracle Cloud Storage folder. You can only see this file if the validation process is successful, and you have access to the Oracle Cloud Storage bucket and folder that you’re trying to send logs to.
        """
        return pulumi.get(self, "oracle_connector")

    @oracle_connector.setter
    def oracle_connector(self, value: Optional[pulumi.Input['DatastreamOracleConnectorArgs']]):
        pulumi.set(self, "oracle_connector", value)

    @property
    @pulumi.getter(name="s3Connector")
    def s3_connector(self) -> Optional[pulumi.Input['DatastreamS3ConnectorArgs']]:
        """
        - (Optional) Specify details about the Amazon S3 connector in a stream. When validating this connector, DataStream uses the provided `access_key` and `secret_access_key` values and saves an `akamai_write_test_2147483647.txt` file in your Amazon S3 folder. You can only see this file if validation succeeds, and you have access to the Amazon S3 bucket and folder that you’re trying to send logs to. The argument includes these sub-arguments:
        """
        return pulumi.get(self, "s3_connector")

    @s3_connector.setter
    def s3_connector(self, value: Optional[pulumi.Input['DatastreamS3ConnectorArgs']]):
        pulumi.set(self, "s3_connector", value)

    @property
    @pulumi.getter(name="splunkConnector")
    def splunk_connector(self) -> Optional[pulumi.Input['DatastreamSplunkConnectorArgs']]:
        """
        Specify details about the Splunk connector in your stream. Note that currently DataStream supports only endpoint URLs ending with `collector/raw`. The argument includes these sub-arguments:
        """
        return pulumi.get(self, "splunk_connector")

    @splunk_connector.setter
    def splunk_connector(self, value: Optional[pulumi.Input['DatastreamSplunkConnectorArgs']]):
        pulumi.set(self, "splunk_connector", value)

    @property
    @pulumi.getter(name="sumologicConnector")
    def sumologic_connector(self) -> Optional[pulumi.Input['DatastreamSumologicConnectorArgs']]:
        """
        Specify details about the Sumo Logic connector in a stream, including:
        """
        return pulumi.get(self, "sumologic_connector")

    @sumologic_connector.setter
    def sumologic_connector(self, value: Optional[pulumi.Input['DatastreamSumologicConnectorArgs']]):
        pulumi.set(self, "sumologic_connector", value)


@pulumi.input_type
class _DatastreamState:
    def __init__(__self__, *,
                 active: Optional[pulumi.Input[bool]] = None,
                 azure_connector: Optional[pulumi.Input['DatastreamAzureConnectorArgs']] = None,
                 config: Optional[pulumi.Input['DatastreamConfigArgs']] = None,
                 contract_id: Optional[pulumi.Input[str]] = None,
                 created_by: Optional[pulumi.Input[str]] = None,
                 created_date: Optional[pulumi.Input[str]] = None,
                 datadog_connector: Optional[pulumi.Input['DatastreamDatadogConnectorArgs']] = None,
                 dataset_fields_ids: Optional[pulumi.Input[Sequence[pulumi.Input[int]]]] = None,
                 email_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 gcs_connector: Optional[pulumi.Input['DatastreamGcsConnectorArgs']] = None,
                 group_id: Optional[pulumi.Input[str]] = None,
                 group_name: Optional[pulumi.Input[str]] = None,
                 https_connector: Optional[pulumi.Input['DatastreamHttpsConnectorArgs']] = None,
                 modified_by: Optional[pulumi.Input[str]] = None,
                 modified_date: Optional[pulumi.Input[str]] = None,
                 oracle_connector: Optional[pulumi.Input['DatastreamOracleConnectorArgs']] = None,
                 papi_json: Optional[pulumi.Input[str]] = None,
                 product_id: Optional[pulumi.Input[str]] = None,
                 product_name: Optional[pulumi.Input[str]] = None,
                 property_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 s3_connector: Optional[pulumi.Input['DatastreamS3ConnectorArgs']] = None,
                 splunk_connector: Optional[pulumi.Input['DatastreamSplunkConnectorArgs']] = None,
                 stream_name: Optional[pulumi.Input[str]] = None,
                 stream_type: Optional[pulumi.Input[str]] = None,
                 stream_version_id: Optional[pulumi.Input[int]] = None,
                 sumologic_connector: Optional[pulumi.Input['DatastreamSumologicConnectorArgs']] = None,
                 template_name: Optional[pulumi.Input[str]] = None):
        """
        Input properties used for looking up and filtering Datastream resources.
        :param pulumi.Input[bool] active: - (Required) Whether you want to start activating the stream when applying the resource. Either `true` for activating the stream upon sending the request or `false` for leaving the stream inactive after the request.
        :param pulumi.Input['DatastreamAzureConnectorArgs'] azure_connector: Specify details about the Azure Storage connector configuration in a data stream. Note that currently DataStream supports only streaming data to [block objects](https://docs.microsoft.com/en-us/rest/api/storageservices/understanding-block-blobs--append-blobs--and-page-blobs). The argument includes these sub-arguments:
        :param pulumi.Input['DatastreamConfigArgs'] config: - (Required) Provides information about the log line configuration, log file format, names of log files sent, and file delivery. The argument includes these sub-arguments:
        :param pulumi.Input[str] contract_id: - (Required) Identifies the contract that has access to the product.
        :param pulumi.Input[str] created_by: The username who created the stream
        :param pulumi.Input[str] created_date: The date and time when the stream was created
        :param pulumi.Input['DatastreamDatadogConnectorArgs'] datadog_connector: Specify details about the Datadog connector in a stream, including:
        :param pulumi.Input[Sequence[pulumi.Input[int]]] dataset_fields_ids: - (Required)	Identifiers of the data set fields within the template that you want to receive in logs. The order of the identifiers define how the value for these fields appears in the log lines. See [Data set parameters](https://techdocs.akamai.com/datastream2/reference/data-set-parameters-1).
        :param pulumi.Input[Sequence[pulumi.Input[str]]] email_ids: - (Optional) A list of email addresses you want to notify about activations and deactivations of the stream.
        :param pulumi.Input['DatastreamGcsConnectorArgs'] gcs_connector: Specify details about the Google Cloud Storage connector you can use in a stream. When validating this connector, DataStream uses the private access key to create an `Akamai_access_verification_<timestamp>.txt` object file in your GCS bucket. You can only see this file if the validation process is successful, and you have access to the Google Cloud Storage bucket where you are trying to send logs. The argument includes these sub-arguments:
        :param pulumi.Input[str] group_id: - (Required) Identifies the group that has access to the product and this stream configuration.
        :param pulumi.Input[str] group_name: The name of the user group for which the stream was created
        :param pulumi.Input['DatastreamHttpsConnectorArgs'] https_connector: Specify details about the custom HTTPS endpoint you can use as a connector for a stream, including:
        :param pulumi.Input[str] modified_by: The username who modified the stream
        :param pulumi.Input[str] modified_date: The date and time when the stream was modified
        :param pulumi.Input['DatastreamOracleConnectorArgs'] oracle_connector: Specify details about the Oracle Cloud Storage connector in a stream. When validating this connector, DataStream uses the provided `access_key` and `secret_access_key` values and tries to save an `Akamai_access_verification_<timestamp>.txt` file in your Oracle Cloud Storage folder. You can only see this file if the validation process is successful, and you have access to the Oracle Cloud Storage bucket and folder that you’re trying to send logs to.
        :param pulumi.Input[str] papi_json: The configuration in JSON format that can be copy-pasted into PAPI configuration to enable datastream behavior
        :param pulumi.Input[str] product_id: The ID of the product for which the stream was created
        :param pulumi.Input[str] product_name: The name of the product for which the stream was created
        :param pulumi.Input[Sequence[pulumi.Input[str]]] property_ids: - (Required) Identifies the properties that you want to monitor in the stream. Note that a stream can only log data for active properties.
        :param pulumi.Input['DatastreamS3ConnectorArgs'] s3_connector: - (Optional) Specify details about the Amazon S3 connector in a stream. When validating this connector, DataStream uses the provided `access_key` and `secret_access_key` values and saves an `akamai_write_test_2147483647.txt` file in your Amazon S3 folder. You can only see this file if validation succeeds, and you have access to the Amazon S3 bucket and folder that you’re trying to send logs to. The argument includes these sub-arguments:
        :param pulumi.Input['DatastreamSplunkConnectorArgs'] splunk_connector: Specify details about the Splunk connector in your stream. Note that currently DataStream supports only endpoint URLs ending with `collector/raw`. The argument includes these sub-arguments:
        :param pulumi.Input[str] stream_name: - (Required) The name of the stream.
        :param pulumi.Input[str] stream_type: - (Required) The type of stream that you want to create. Currently, `RAW_LOGS` is the only possible stream type.
        :param pulumi.Input[int] stream_version_id: Identifies the configuration version of the stream
        :param pulumi.Input['DatastreamSumologicConnectorArgs'] sumologic_connector: Specify details about the Sumo Logic connector in a stream, including:
        :param pulumi.Input[str] template_name: - (Required) The name of the data set template available for the product that you want to use in the stream. Currently, `EDGE_LOGS` is the only data set template available.
        """
        if active is not None:
            pulumi.set(__self__, "active", active)
        if azure_connector is not None:
            pulumi.set(__self__, "azure_connector", azure_connector)
        if config is not None:
            pulumi.set(__self__, "config", config)
        if contract_id is not None:
            pulumi.set(__self__, "contract_id", contract_id)
        if created_by is not None:
            pulumi.set(__self__, "created_by", created_by)
        if created_date is not None:
            pulumi.set(__self__, "created_date", created_date)
        if datadog_connector is not None:
            pulumi.set(__self__, "datadog_connector", datadog_connector)
        if dataset_fields_ids is not None:
            pulumi.set(__self__, "dataset_fields_ids", dataset_fields_ids)
        if email_ids is not None:
            pulumi.set(__self__, "email_ids", email_ids)
        if gcs_connector is not None:
            pulumi.set(__self__, "gcs_connector", gcs_connector)
        if group_id is not None:
            pulumi.set(__self__, "group_id", group_id)
        if group_name is not None:
            pulumi.set(__self__, "group_name", group_name)
        if https_connector is not None:
            pulumi.set(__self__, "https_connector", https_connector)
        if modified_by is not None:
            pulumi.set(__self__, "modified_by", modified_by)
        if modified_date is not None:
            pulumi.set(__self__, "modified_date", modified_date)
        if oracle_connector is not None:
            pulumi.set(__self__, "oracle_connector", oracle_connector)
        if papi_json is not None:
            pulumi.set(__self__, "papi_json", papi_json)
        if product_id is not None:
            pulumi.set(__self__, "product_id", product_id)
        if product_name is not None:
            pulumi.set(__self__, "product_name", product_name)
        if property_ids is not None:
            pulumi.set(__self__, "property_ids", property_ids)
        if s3_connector is not None:
            pulumi.set(__self__, "s3_connector", s3_connector)
        if splunk_connector is not None:
            pulumi.set(__self__, "splunk_connector", splunk_connector)
        if stream_name is not None:
            pulumi.set(__self__, "stream_name", stream_name)
        if stream_type is not None:
            pulumi.set(__self__, "stream_type", stream_type)
        if stream_version_id is not None:
            pulumi.set(__self__, "stream_version_id", stream_version_id)
        if sumologic_connector is not None:
            pulumi.set(__self__, "sumologic_connector", sumologic_connector)
        if template_name is not None:
            pulumi.set(__self__, "template_name", template_name)

    @property
    @pulumi.getter
    def active(self) -> Optional[pulumi.Input[bool]]:
        """
        - (Required) Whether you want to start activating the stream when applying the resource. Either `true` for activating the stream upon sending the request or `false` for leaving the stream inactive after the request.
        """
        return pulumi.get(self, "active")

    @active.setter
    def active(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "active", value)

    @property
    @pulumi.getter(name="azureConnector")
    def azure_connector(self) -> Optional[pulumi.Input['DatastreamAzureConnectorArgs']]:
        """
        Specify details about the Azure Storage connector configuration in a data stream. Note that currently DataStream supports only streaming data to [block objects](https://docs.microsoft.com/en-us/rest/api/storageservices/understanding-block-blobs--append-blobs--and-page-blobs). The argument includes these sub-arguments:
        """
        return pulumi.get(self, "azure_connector")

    @azure_connector.setter
    def azure_connector(self, value: Optional[pulumi.Input['DatastreamAzureConnectorArgs']]):
        pulumi.set(self, "azure_connector", value)

    @property
    @pulumi.getter
    def config(self) -> Optional[pulumi.Input['DatastreamConfigArgs']]:
        """
        - (Required) Provides information about the log line configuration, log file format, names of log files sent, and file delivery. The argument includes these sub-arguments:
        """
        return pulumi.get(self, "config")

    @config.setter
    def config(self, value: Optional[pulumi.Input['DatastreamConfigArgs']]):
        pulumi.set(self, "config", value)

    @property
    @pulumi.getter(name="contractId")
    def contract_id(self) -> Optional[pulumi.Input[str]]:
        """
        - (Required) Identifies the contract that has access to the product.
        """
        return pulumi.get(self, "contract_id")

    @contract_id.setter
    def contract_id(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "contract_id", value)

    @property
    @pulumi.getter(name="createdBy")
    def created_by(self) -> Optional[pulumi.Input[str]]:
        """
        The username who created the stream
        """
        return pulumi.get(self, "created_by")

    @created_by.setter
    def created_by(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "created_by", value)

    @property
    @pulumi.getter(name="createdDate")
    def created_date(self) -> Optional[pulumi.Input[str]]:
        """
        The date and time when the stream was created
        """
        return pulumi.get(self, "created_date")

    @created_date.setter
    def created_date(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "created_date", value)

    @property
    @pulumi.getter(name="datadogConnector")
    def datadog_connector(self) -> Optional[pulumi.Input['DatastreamDatadogConnectorArgs']]:
        """
        Specify details about the Datadog connector in a stream, including:
        """
        return pulumi.get(self, "datadog_connector")

    @datadog_connector.setter
    def datadog_connector(self, value: Optional[pulumi.Input['DatastreamDatadogConnectorArgs']]):
        pulumi.set(self, "datadog_connector", value)

    @property
    @pulumi.getter(name="datasetFieldsIds")
    def dataset_fields_ids(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[int]]]]:
        """
        - (Required)	Identifiers of the data set fields within the template that you want to receive in logs. The order of the identifiers define how the value for these fields appears in the log lines. See [Data set parameters](https://techdocs.akamai.com/datastream2/reference/data-set-parameters-1).
        """
        return pulumi.get(self, "dataset_fields_ids")

    @dataset_fields_ids.setter
    def dataset_fields_ids(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[int]]]]):
        pulumi.set(self, "dataset_fields_ids", value)

    @property
    @pulumi.getter(name="emailIds")
    def email_ids(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        - (Optional) A list of email addresses you want to notify about activations and deactivations of the stream.
        """
        return pulumi.get(self, "email_ids")

    @email_ids.setter
    def email_ids(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "email_ids", value)

    @property
    @pulumi.getter(name="gcsConnector")
    def gcs_connector(self) -> Optional[pulumi.Input['DatastreamGcsConnectorArgs']]:
        """
        Specify details about the Google Cloud Storage connector you can use in a stream. When validating this connector, DataStream uses the private access key to create an `Akamai_access_verification_<timestamp>.txt` object file in your GCS bucket. You can only see this file if the validation process is successful, and you have access to the Google Cloud Storage bucket where you are trying to send logs. The argument includes these sub-arguments:
        """
        return pulumi.get(self, "gcs_connector")

    @gcs_connector.setter
    def gcs_connector(self, value: Optional[pulumi.Input['DatastreamGcsConnectorArgs']]):
        pulumi.set(self, "gcs_connector", value)

    @property
    @pulumi.getter(name="groupId")
    def group_id(self) -> Optional[pulumi.Input[str]]:
        """
        - (Required) Identifies the group that has access to the product and this stream configuration.
        """
        return pulumi.get(self, "group_id")

    @group_id.setter
    def group_id(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "group_id", value)

    @property
    @pulumi.getter(name="groupName")
    def group_name(self) -> Optional[pulumi.Input[str]]:
        """
        The name of the user group for which the stream was created
        """
        return pulumi.get(self, "group_name")

    @group_name.setter
    def group_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "group_name", value)

    @property
    @pulumi.getter(name="httpsConnector")
    def https_connector(self) -> Optional[pulumi.Input['DatastreamHttpsConnectorArgs']]:
        """
        Specify details about the custom HTTPS endpoint you can use as a connector for a stream, including:
        """
        return pulumi.get(self, "https_connector")

    @https_connector.setter
    def https_connector(self, value: Optional[pulumi.Input['DatastreamHttpsConnectorArgs']]):
        pulumi.set(self, "https_connector", value)

    @property
    @pulumi.getter(name="modifiedBy")
    def modified_by(self) -> Optional[pulumi.Input[str]]:
        """
        The username who modified the stream
        """
        return pulumi.get(self, "modified_by")

    @modified_by.setter
    def modified_by(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "modified_by", value)

    @property
    @pulumi.getter(name="modifiedDate")
    def modified_date(self) -> Optional[pulumi.Input[str]]:
        """
        The date and time when the stream was modified
        """
        return pulumi.get(self, "modified_date")

    @modified_date.setter
    def modified_date(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "modified_date", value)

    @property
    @pulumi.getter(name="oracleConnector")
    def oracle_connector(self) -> Optional[pulumi.Input['DatastreamOracleConnectorArgs']]:
        """
        Specify details about the Oracle Cloud Storage connector in a stream. When validating this connector, DataStream uses the provided `access_key` and `secret_access_key` values and tries to save an `Akamai_access_verification_<timestamp>.txt` file in your Oracle Cloud Storage folder. You can only see this file if the validation process is successful, and you have access to the Oracle Cloud Storage bucket and folder that you’re trying to send logs to.
        """
        return pulumi.get(self, "oracle_connector")

    @oracle_connector.setter
    def oracle_connector(self, value: Optional[pulumi.Input['DatastreamOracleConnectorArgs']]):
        pulumi.set(self, "oracle_connector", value)

    @property
    @pulumi.getter(name="papiJson")
    def papi_json(self) -> Optional[pulumi.Input[str]]:
        """
        The configuration in JSON format that can be copy-pasted into PAPI configuration to enable datastream behavior
        """
        return pulumi.get(self, "papi_json")

    @papi_json.setter
    def papi_json(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "papi_json", value)

    @property
    @pulumi.getter(name="productId")
    def product_id(self) -> Optional[pulumi.Input[str]]:
        """
        The ID of the product for which the stream was created
        """
        return pulumi.get(self, "product_id")

    @product_id.setter
    def product_id(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "product_id", value)

    @property
    @pulumi.getter(name="productName")
    def product_name(self) -> Optional[pulumi.Input[str]]:
        """
        The name of the product for which the stream was created
        """
        return pulumi.get(self, "product_name")

    @product_name.setter
    def product_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "product_name", value)

    @property
    @pulumi.getter(name="propertyIds")
    def property_ids(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        - (Required) Identifies the properties that you want to monitor in the stream. Note that a stream can only log data for active properties.
        """
        return pulumi.get(self, "property_ids")

    @property_ids.setter
    def property_ids(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "property_ids", value)

    @property
    @pulumi.getter(name="s3Connector")
    def s3_connector(self) -> Optional[pulumi.Input['DatastreamS3ConnectorArgs']]:
        """
        - (Optional) Specify details about the Amazon S3 connector in a stream. When validating this connector, DataStream uses the provided `access_key` and `secret_access_key` values and saves an `akamai_write_test_2147483647.txt` file in your Amazon S3 folder. You can only see this file if validation succeeds, and you have access to the Amazon S3 bucket and folder that you’re trying to send logs to. The argument includes these sub-arguments:
        """
        return pulumi.get(self, "s3_connector")

    @s3_connector.setter
    def s3_connector(self, value: Optional[pulumi.Input['DatastreamS3ConnectorArgs']]):
        pulumi.set(self, "s3_connector", value)

    @property
    @pulumi.getter(name="splunkConnector")
    def splunk_connector(self) -> Optional[pulumi.Input['DatastreamSplunkConnectorArgs']]:
        """
        Specify details about the Splunk connector in your stream. Note that currently DataStream supports only endpoint URLs ending with `collector/raw`. The argument includes these sub-arguments:
        """
        return pulumi.get(self, "splunk_connector")

    @splunk_connector.setter
    def splunk_connector(self, value: Optional[pulumi.Input['DatastreamSplunkConnectorArgs']]):
        pulumi.set(self, "splunk_connector", value)

    @property
    @pulumi.getter(name="streamName")
    def stream_name(self) -> Optional[pulumi.Input[str]]:
        """
        - (Required) The name of the stream.
        """
        return pulumi.get(self, "stream_name")

    @stream_name.setter
    def stream_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "stream_name", value)

    @property
    @pulumi.getter(name="streamType")
    def stream_type(self) -> Optional[pulumi.Input[str]]:
        """
        - (Required) The type of stream that you want to create. Currently, `RAW_LOGS` is the only possible stream type.
        """
        return pulumi.get(self, "stream_type")

    @stream_type.setter
    def stream_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "stream_type", value)

    @property
    @pulumi.getter(name="streamVersionId")
    def stream_version_id(self) -> Optional[pulumi.Input[int]]:
        """
        Identifies the configuration version of the stream
        """
        return pulumi.get(self, "stream_version_id")

    @stream_version_id.setter
    def stream_version_id(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "stream_version_id", value)

    @property
    @pulumi.getter(name="sumologicConnector")
    def sumologic_connector(self) -> Optional[pulumi.Input['DatastreamSumologicConnectorArgs']]:
        """
        Specify details about the Sumo Logic connector in a stream, including:
        """
        return pulumi.get(self, "sumologic_connector")

    @sumologic_connector.setter
    def sumologic_connector(self, value: Optional[pulumi.Input['DatastreamSumologicConnectorArgs']]):
        pulumi.set(self, "sumologic_connector", value)

    @property
    @pulumi.getter(name="templateName")
    def template_name(self) -> Optional[pulumi.Input[str]]:
        """
        - (Required) The name of the data set template available for the product that you want to use in the stream. Currently, `EDGE_LOGS` is the only data set template available.
        """
        return pulumi.get(self, "template_name")

    @template_name.setter
    def template_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "template_name", value)


class Datastream(pulumi.CustomResource):
    @overload
    def __init__(__self__,
                 resource_name: str,
                 opts: Optional[pulumi.ResourceOptions] = None,
                 active: Optional[pulumi.Input[bool]] = None,
                 azure_connector: Optional[pulumi.Input[pulumi.InputType['DatastreamAzureConnectorArgs']]] = None,
                 config: Optional[pulumi.Input[pulumi.InputType['DatastreamConfigArgs']]] = None,
                 contract_id: Optional[pulumi.Input[str]] = None,
                 datadog_connector: Optional[pulumi.Input[pulumi.InputType['DatastreamDatadogConnectorArgs']]] = None,
                 dataset_fields_ids: Optional[pulumi.Input[Sequence[pulumi.Input[int]]]] = None,
                 email_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 gcs_connector: Optional[pulumi.Input[pulumi.InputType['DatastreamGcsConnectorArgs']]] = None,
                 group_id: Optional[pulumi.Input[str]] = None,
                 https_connector: Optional[pulumi.Input[pulumi.InputType['DatastreamHttpsConnectorArgs']]] = None,
                 oracle_connector: Optional[pulumi.Input[pulumi.InputType['DatastreamOracleConnectorArgs']]] = None,
                 property_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 s3_connector: Optional[pulumi.Input[pulumi.InputType['DatastreamS3ConnectorArgs']]] = None,
                 splunk_connector: Optional[pulumi.Input[pulumi.InputType['DatastreamSplunkConnectorArgs']]] = None,
                 stream_name: Optional[pulumi.Input[str]] = None,
                 stream_type: Optional[pulumi.Input[str]] = None,
                 sumologic_connector: Optional[pulumi.Input[pulumi.InputType['DatastreamSumologicConnectorArgs']]] = None,
                 template_name: Optional[pulumi.Input[str]] = None,
                 __props__=None):
        """
        ## Import

        Basic usagehcl resource "akamai_datastream" "example" {

        # (resource arguments)

         } You can import your Akamai DataStream configuration using a stream version ID. For example

        ```sh
         $ pulumi import akamai:index/datastream:Datastream example 1234
        ```

         ~> **IMPORTANT:** For security reasons, this command doesn't import any secrets you specify for your connector. To make sure the state file includes complete data, use this resource to manually add the arguments marked **Secret** above.

        :param str resource_name: The name of the resource.
        :param pulumi.ResourceOptions opts: Options for the resource.
        :param pulumi.Input[bool] active: - (Required) Whether you want to start activating the stream when applying the resource. Either `true` for activating the stream upon sending the request or `false` for leaving the stream inactive after the request.
        :param pulumi.Input[pulumi.InputType['DatastreamAzureConnectorArgs']] azure_connector: Specify details about the Azure Storage connector configuration in a data stream. Note that currently DataStream supports only streaming data to [block objects](https://docs.microsoft.com/en-us/rest/api/storageservices/understanding-block-blobs--append-blobs--and-page-blobs). The argument includes these sub-arguments:
        :param pulumi.Input[pulumi.InputType['DatastreamConfigArgs']] config: - (Required) Provides information about the log line configuration, log file format, names of log files sent, and file delivery. The argument includes these sub-arguments:
        :param pulumi.Input[str] contract_id: - (Required) Identifies the contract that has access to the product.
        :param pulumi.Input[pulumi.InputType['DatastreamDatadogConnectorArgs']] datadog_connector: Specify details about the Datadog connector in a stream, including:
        :param pulumi.Input[Sequence[pulumi.Input[int]]] dataset_fields_ids: - (Required)	Identifiers of the data set fields within the template that you want to receive in logs. The order of the identifiers define how the value for these fields appears in the log lines. See [Data set parameters](https://techdocs.akamai.com/datastream2/reference/data-set-parameters-1).
        :param pulumi.Input[Sequence[pulumi.Input[str]]] email_ids: - (Optional) A list of email addresses you want to notify about activations and deactivations of the stream.
        :param pulumi.Input[pulumi.InputType['DatastreamGcsConnectorArgs']] gcs_connector: Specify details about the Google Cloud Storage connector you can use in a stream. When validating this connector, DataStream uses the private access key to create an `Akamai_access_verification_<timestamp>.txt` object file in your GCS bucket. You can only see this file if the validation process is successful, and you have access to the Google Cloud Storage bucket where you are trying to send logs. The argument includes these sub-arguments:
        :param pulumi.Input[str] group_id: - (Required) Identifies the group that has access to the product and this stream configuration.
        :param pulumi.Input[pulumi.InputType['DatastreamHttpsConnectorArgs']] https_connector: Specify details about the custom HTTPS endpoint you can use as a connector for a stream, including:
        :param pulumi.Input[pulumi.InputType['DatastreamOracleConnectorArgs']] oracle_connector: Specify details about the Oracle Cloud Storage connector in a stream. When validating this connector, DataStream uses the provided `access_key` and `secret_access_key` values and tries to save an `Akamai_access_verification_<timestamp>.txt` file in your Oracle Cloud Storage folder. You can only see this file if the validation process is successful, and you have access to the Oracle Cloud Storage bucket and folder that you’re trying to send logs to.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] property_ids: - (Required) Identifies the properties that you want to monitor in the stream. Note that a stream can only log data for active properties.
        :param pulumi.Input[pulumi.InputType['DatastreamS3ConnectorArgs']] s3_connector: - (Optional) Specify details about the Amazon S3 connector in a stream. When validating this connector, DataStream uses the provided `access_key` and `secret_access_key` values and saves an `akamai_write_test_2147483647.txt` file in your Amazon S3 folder. You can only see this file if validation succeeds, and you have access to the Amazon S3 bucket and folder that you’re trying to send logs to. The argument includes these sub-arguments:
        :param pulumi.Input[pulumi.InputType['DatastreamSplunkConnectorArgs']] splunk_connector: Specify details about the Splunk connector in your stream. Note that currently DataStream supports only endpoint URLs ending with `collector/raw`. The argument includes these sub-arguments:
        :param pulumi.Input[str] stream_name: - (Required) The name of the stream.
        :param pulumi.Input[str] stream_type: - (Required) The type of stream that you want to create. Currently, `RAW_LOGS` is the only possible stream type.
        :param pulumi.Input[pulumi.InputType['DatastreamSumologicConnectorArgs']] sumologic_connector: Specify details about the Sumo Logic connector in a stream, including:
        :param pulumi.Input[str] template_name: - (Required) The name of the data set template available for the product that you want to use in the stream. Currently, `EDGE_LOGS` is the only data set template available.
        """
        ...
    @overload
    def __init__(__self__,
                 resource_name: str,
                 args: DatastreamArgs,
                 opts: Optional[pulumi.ResourceOptions] = None):
        """
        ## Import

        Basic usagehcl resource "akamai_datastream" "example" {

        # (resource arguments)

         } You can import your Akamai DataStream configuration using a stream version ID. For example

        ```sh
         $ pulumi import akamai:index/datastream:Datastream example 1234
        ```

         ~> **IMPORTANT:** For security reasons, this command doesn't import any secrets you specify for your connector. To make sure the state file includes complete data, use this resource to manually add the arguments marked **Secret** above.

        :param str resource_name: The name of the resource.
        :param DatastreamArgs args: The arguments to use to populate this resource's properties.
        :param pulumi.ResourceOptions opts: Options for the resource.
        """
        ...
    def __init__(__self__, resource_name: str, *args, **kwargs):
        resource_args, opts = _utilities.get_resource_args_opts(DatastreamArgs, pulumi.ResourceOptions, *args, **kwargs)
        if resource_args is not None:
            __self__._internal_init(resource_name, opts, **resource_args.__dict__)
        else:
            __self__._internal_init(resource_name, *args, **kwargs)

    def _internal_init(__self__,
                 resource_name: str,
                 opts: Optional[pulumi.ResourceOptions] = None,
                 active: Optional[pulumi.Input[bool]] = None,
                 azure_connector: Optional[pulumi.Input[pulumi.InputType['DatastreamAzureConnectorArgs']]] = None,
                 config: Optional[pulumi.Input[pulumi.InputType['DatastreamConfigArgs']]] = None,
                 contract_id: Optional[pulumi.Input[str]] = None,
                 datadog_connector: Optional[pulumi.Input[pulumi.InputType['DatastreamDatadogConnectorArgs']]] = None,
                 dataset_fields_ids: Optional[pulumi.Input[Sequence[pulumi.Input[int]]]] = None,
                 email_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 gcs_connector: Optional[pulumi.Input[pulumi.InputType['DatastreamGcsConnectorArgs']]] = None,
                 group_id: Optional[pulumi.Input[str]] = None,
                 https_connector: Optional[pulumi.Input[pulumi.InputType['DatastreamHttpsConnectorArgs']]] = None,
                 oracle_connector: Optional[pulumi.Input[pulumi.InputType['DatastreamOracleConnectorArgs']]] = None,
                 property_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 s3_connector: Optional[pulumi.Input[pulumi.InputType['DatastreamS3ConnectorArgs']]] = None,
                 splunk_connector: Optional[pulumi.Input[pulumi.InputType['DatastreamSplunkConnectorArgs']]] = None,
                 stream_name: Optional[pulumi.Input[str]] = None,
                 stream_type: Optional[pulumi.Input[str]] = None,
                 sumologic_connector: Optional[pulumi.Input[pulumi.InputType['DatastreamSumologicConnectorArgs']]] = None,
                 template_name: Optional[pulumi.Input[str]] = None,
                 __props__=None):
        if opts is None:
            opts = pulumi.ResourceOptions()
        if not isinstance(opts, pulumi.ResourceOptions):
            raise TypeError('Expected resource options to be a ResourceOptions instance')
        if opts.version is None:
            opts.version = _utilities.get_version()
        if opts.id is None:
            if __props__ is not None:
                raise TypeError('__props__ is only valid when passed in combination with a valid opts.id to get an existing resource')
            __props__ = DatastreamArgs.__new__(DatastreamArgs)

            if active is None and not opts.urn:
                raise TypeError("Missing required property 'active'")
            __props__.__dict__["active"] = active
            __props__.__dict__["azure_connector"] = azure_connector
            if config is None and not opts.urn:
                raise TypeError("Missing required property 'config'")
            __props__.__dict__["config"] = config
            if contract_id is None and not opts.urn:
                raise TypeError("Missing required property 'contract_id'")
            __props__.__dict__["contract_id"] = contract_id
            __props__.__dict__["datadog_connector"] = datadog_connector
            if dataset_fields_ids is None and not opts.urn:
                raise TypeError("Missing required property 'dataset_fields_ids'")
            __props__.__dict__["dataset_fields_ids"] = dataset_fields_ids
            __props__.__dict__["email_ids"] = email_ids
            __props__.__dict__["gcs_connector"] = gcs_connector
            if group_id is None and not opts.urn:
                raise TypeError("Missing required property 'group_id'")
            __props__.__dict__["group_id"] = group_id
            __props__.__dict__["https_connector"] = https_connector
            __props__.__dict__["oracle_connector"] = oracle_connector
            if property_ids is None and not opts.urn:
                raise TypeError("Missing required property 'property_ids'")
            __props__.__dict__["property_ids"] = property_ids
            __props__.__dict__["s3_connector"] = s3_connector
            __props__.__dict__["splunk_connector"] = splunk_connector
            if stream_name is None and not opts.urn:
                raise TypeError("Missing required property 'stream_name'")
            __props__.__dict__["stream_name"] = stream_name
            if stream_type is None and not opts.urn:
                raise TypeError("Missing required property 'stream_type'")
            __props__.__dict__["stream_type"] = stream_type
            __props__.__dict__["sumologic_connector"] = sumologic_connector
            if template_name is None and not opts.urn:
                raise TypeError("Missing required property 'template_name'")
            __props__.__dict__["template_name"] = template_name
            __props__.__dict__["created_by"] = None
            __props__.__dict__["created_date"] = None
            __props__.__dict__["group_name"] = None
            __props__.__dict__["modified_by"] = None
            __props__.__dict__["modified_date"] = None
            __props__.__dict__["papi_json"] = None
            __props__.__dict__["product_id"] = None
            __props__.__dict__["product_name"] = None
            __props__.__dict__["stream_version_id"] = None
        super(Datastream, __self__).__init__(
            'akamai:index/datastream:Datastream',
            resource_name,
            __props__,
            opts)

    @staticmethod
    def get(resource_name: str,
            id: pulumi.Input[str],
            opts: Optional[pulumi.ResourceOptions] = None,
            active: Optional[pulumi.Input[bool]] = None,
            azure_connector: Optional[pulumi.Input[pulumi.InputType['DatastreamAzureConnectorArgs']]] = None,
            config: Optional[pulumi.Input[pulumi.InputType['DatastreamConfigArgs']]] = None,
            contract_id: Optional[pulumi.Input[str]] = None,
            created_by: Optional[pulumi.Input[str]] = None,
            created_date: Optional[pulumi.Input[str]] = None,
            datadog_connector: Optional[pulumi.Input[pulumi.InputType['DatastreamDatadogConnectorArgs']]] = None,
            dataset_fields_ids: Optional[pulumi.Input[Sequence[pulumi.Input[int]]]] = None,
            email_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
            gcs_connector: Optional[pulumi.Input[pulumi.InputType['DatastreamGcsConnectorArgs']]] = None,
            group_id: Optional[pulumi.Input[str]] = None,
            group_name: Optional[pulumi.Input[str]] = None,
            https_connector: Optional[pulumi.Input[pulumi.InputType['DatastreamHttpsConnectorArgs']]] = None,
            modified_by: Optional[pulumi.Input[str]] = None,
            modified_date: Optional[pulumi.Input[str]] = None,
            oracle_connector: Optional[pulumi.Input[pulumi.InputType['DatastreamOracleConnectorArgs']]] = None,
            papi_json: Optional[pulumi.Input[str]] = None,
            product_id: Optional[pulumi.Input[str]] = None,
            product_name: Optional[pulumi.Input[str]] = None,
            property_ids: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
            s3_connector: Optional[pulumi.Input[pulumi.InputType['DatastreamS3ConnectorArgs']]] = None,
            splunk_connector: Optional[pulumi.Input[pulumi.InputType['DatastreamSplunkConnectorArgs']]] = None,
            stream_name: Optional[pulumi.Input[str]] = None,
            stream_type: Optional[pulumi.Input[str]] = None,
            stream_version_id: Optional[pulumi.Input[int]] = None,
            sumologic_connector: Optional[pulumi.Input[pulumi.InputType['DatastreamSumologicConnectorArgs']]] = None,
            template_name: Optional[pulumi.Input[str]] = None) -> 'Datastream':
        """
        Get an existing Datastream resource's state with the given name, id, and optional extra
        properties used to qualify the lookup.

        :param str resource_name: The unique name of the resulting resource.
        :param pulumi.Input[str] id: The unique provider ID of the resource to lookup.
        :param pulumi.ResourceOptions opts: Options for the resource.
        :param pulumi.Input[bool] active: - (Required) Whether you want to start activating the stream when applying the resource. Either `true` for activating the stream upon sending the request or `false` for leaving the stream inactive after the request.
        :param pulumi.Input[pulumi.InputType['DatastreamAzureConnectorArgs']] azure_connector: Specify details about the Azure Storage connector configuration in a data stream. Note that currently DataStream supports only streaming data to [block objects](https://docs.microsoft.com/en-us/rest/api/storageservices/understanding-block-blobs--append-blobs--and-page-blobs). The argument includes these sub-arguments:
        :param pulumi.Input[pulumi.InputType['DatastreamConfigArgs']] config: - (Required) Provides information about the log line configuration, log file format, names of log files sent, and file delivery. The argument includes these sub-arguments:
        :param pulumi.Input[str] contract_id: - (Required) Identifies the contract that has access to the product.
        :param pulumi.Input[str] created_by: The username who created the stream
        :param pulumi.Input[str] created_date: The date and time when the stream was created
        :param pulumi.Input[pulumi.InputType['DatastreamDatadogConnectorArgs']] datadog_connector: Specify details about the Datadog connector in a stream, including:
        :param pulumi.Input[Sequence[pulumi.Input[int]]] dataset_fields_ids: - (Required)	Identifiers of the data set fields within the template that you want to receive in logs. The order of the identifiers define how the value for these fields appears in the log lines. See [Data set parameters](https://techdocs.akamai.com/datastream2/reference/data-set-parameters-1).
        :param pulumi.Input[Sequence[pulumi.Input[str]]] email_ids: - (Optional) A list of email addresses you want to notify about activations and deactivations of the stream.
        :param pulumi.Input[pulumi.InputType['DatastreamGcsConnectorArgs']] gcs_connector: Specify details about the Google Cloud Storage connector you can use in a stream. When validating this connector, DataStream uses the private access key to create an `Akamai_access_verification_<timestamp>.txt` object file in your GCS bucket. You can only see this file if the validation process is successful, and you have access to the Google Cloud Storage bucket where you are trying to send logs. The argument includes these sub-arguments:
        :param pulumi.Input[str] group_id: - (Required) Identifies the group that has access to the product and this stream configuration.
        :param pulumi.Input[str] group_name: The name of the user group for which the stream was created
        :param pulumi.Input[pulumi.InputType['DatastreamHttpsConnectorArgs']] https_connector: Specify details about the custom HTTPS endpoint you can use as a connector for a stream, including:
        :param pulumi.Input[str] modified_by: The username who modified the stream
        :param pulumi.Input[str] modified_date: The date and time when the stream was modified
        :param pulumi.Input[pulumi.InputType['DatastreamOracleConnectorArgs']] oracle_connector: Specify details about the Oracle Cloud Storage connector in a stream. When validating this connector, DataStream uses the provided `access_key` and `secret_access_key` values and tries to save an `Akamai_access_verification_<timestamp>.txt` file in your Oracle Cloud Storage folder. You can only see this file if the validation process is successful, and you have access to the Oracle Cloud Storage bucket and folder that you’re trying to send logs to.
        :param pulumi.Input[str] papi_json: The configuration in JSON format that can be copy-pasted into PAPI configuration to enable datastream behavior
        :param pulumi.Input[str] product_id: The ID of the product for which the stream was created
        :param pulumi.Input[str] product_name: The name of the product for which the stream was created
        :param pulumi.Input[Sequence[pulumi.Input[str]]] property_ids: - (Required) Identifies the properties that you want to monitor in the stream. Note that a stream can only log data for active properties.
        :param pulumi.Input[pulumi.InputType['DatastreamS3ConnectorArgs']] s3_connector: - (Optional) Specify details about the Amazon S3 connector in a stream. When validating this connector, DataStream uses the provided `access_key` and `secret_access_key` values and saves an `akamai_write_test_2147483647.txt` file in your Amazon S3 folder. You can only see this file if validation succeeds, and you have access to the Amazon S3 bucket and folder that you’re trying to send logs to. The argument includes these sub-arguments:
        :param pulumi.Input[pulumi.InputType['DatastreamSplunkConnectorArgs']] splunk_connector: Specify details about the Splunk connector in your stream. Note that currently DataStream supports only endpoint URLs ending with `collector/raw`. The argument includes these sub-arguments:
        :param pulumi.Input[str] stream_name: - (Required) The name of the stream.
        :param pulumi.Input[str] stream_type: - (Required) The type of stream that you want to create. Currently, `RAW_LOGS` is the only possible stream type.
        :param pulumi.Input[int] stream_version_id: Identifies the configuration version of the stream
        :param pulumi.Input[pulumi.InputType['DatastreamSumologicConnectorArgs']] sumologic_connector: Specify details about the Sumo Logic connector in a stream, including:
        :param pulumi.Input[str] template_name: - (Required) The name of the data set template available for the product that you want to use in the stream. Currently, `EDGE_LOGS` is the only data set template available.
        """
        opts = pulumi.ResourceOptions.merge(opts, pulumi.ResourceOptions(id=id))

        __props__ = _DatastreamState.__new__(_DatastreamState)

        __props__.__dict__["active"] = active
        __props__.__dict__["azure_connector"] = azure_connector
        __props__.__dict__["config"] = config
        __props__.__dict__["contract_id"] = contract_id
        __props__.__dict__["created_by"] = created_by
        __props__.__dict__["created_date"] = created_date
        __props__.__dict__["datadog_connector"] = datadog_connector
        __props__.__dict__["dataset_fields_ids"] = dataset_fields_ids
        __props__.__dict__["email_ids"] = email_ids
        __props__.__dict__["gcs_connector"] = gcs_connector
        __props__.__dict__["group_id"] = group_id
        __props__.__dict__["group_name"] = group_name
        __props__.__dict__["https_connector"] = https_connector
        __props__.__dict__["modified_by"] = modified_by
        __props__.__dict__["modified_date"] = modified_date
        __props__.__dict__["oracle_connector"] = oracle_connector
        __props__.__dict__["papi_json"] = papi_json
        __props__.__dict__["product_id"] = product_id
        __props__.__dict__["product_name"] = product_name
        __props__.__dict__["property_ids"] = property_ids
        __props__.__dict__["s3_connector"] = s3_connector
        __props__.__dict__["splunk_connector"] = splunk_connector
        __props__.__dict__["stream_name"] = stream_name
        __props__.__dict__["stream_type"] = stream_type
        __props__.__dict__["stream_version_id"] = stream_version_id
        __props__.__dict__["sumologic_connector"] = sumologic_connector
        __props__.__dict__["template_name"] = template_name
        return Datastream(resource_name, opts=opts, __props__=__props__)

    @property
    @pulumi.getter
    def active(self) -> pulumi.Output[bool]:
        """
        - (Required) Whether you want to start activating the stream when applying the resource. Either `true` for activating the stream upon sending the request or `false` for leaving the stream inactive after the request.
        """
        return pulumi.get(self, "active")

    @property
    @pulumi.getter(name="azureConnector")
    def azure_connector(self) -> pulumi.Output[Optional['outputs.DatastreamAzureConnector']]:
        """
        Specify details about the Azure Storage connector configuration in a data stream. Note that currently DataStream supports only streaming data to [block objects](https://docs.microsoft.com/en-us/rest/api/storageservices/understanding-block-blobs--append-blobs--and-page-blobs). The argument includes these sub-arguments:
        """
        return pulumi.get(self, "azure_connector")

    @property
    @pulumi.getter
    def config(self) -> pulumi.Output['outputs.DatastreamConfig']:
        """
        - (Required) Provides information about the log line configuration, log file format, names of log files sent, and file delivery. The argument includes these sub-arguments:
        """
        return pulumi.get(self, "config")

    @property
    @pulumi.getter(name="contractId")
    def contract_id(self) -> pulumi.Output[str]:
        """
        - (Required) Identifies the contract that has access to the product.
        """
        return pulumi.get(self, "contract_id")

    @property
    @pulumi.getter(name="createdBy")
    def created_by(self) -> pulumi.Output[str]:
        """
        The username who created the stream
        """
        return pulumi.get(self, "created_by")

    @property
    @pulumi.getter(name="createdDate")
    def created_date(self) -> pulumi.Output[str]:
        """
        The date and time when the stream was created
        """
        return pulumi.get(self, "created_date")

    @property
    @pulumi.getter(name="datadogConnector")
    def datadog_connector(self) -> pulumi.Output[Optional['outputs.DatastreamDatadogConnector']]:
        """
        Specify details about the Datadog connector in a stream, including:
        """
        return pulumi.get(self, "datadog_connector")

    @property
    @pulumi.getter(name="datasetFieldsIds")
    def dataset_fields_ids(self) -> pulumi.Output[Sequence[int]]:
        """
        - (Required)	Identifiers of the data set fields within the template that you want to receive in logs. The order of the identifiers define how the value for these fields appears in the log lines. See [Data set parameters](https://techdocs.akamai.com/datastream2/reference/data-set-parameters-1).
        """
        return pulumi.get(self, "dataset_fields_ids")

    @property
    @pulumi.getter(name="emailIds")
    def email_ids(self) -> pulumi.Output[Optional[Sequence[str]]]:
        """
        - (Optional) A list of email addresses you want to notify about activations and deactivations of the stream.
        """
        return pulumi.get(self, "email_ids")

    @property
    @pulumi.getter(name="gcsConnector")
    def gcs_connector(self) -> pulumi.Output[Optional['outputs.DatastreamGcsConnector']]:
        """
        Specify details about the Google Cloud Storage connector you can use in a stream. When validating this connector, DataStream uses the private access key to create an `Akamai_access_verification_<timestamp>.txt` object file in your GCS bucket. You can only see this file if the validation process is successful, and you have access to the Google Cloud Storage bucket where you are trying to send logs. The argument includes these sub-arguments:
        """
        return pulumi.get(self, "gcs_connector")

    @property
    @pulumi.getter(name="groupId")
    def group_id(self) -> pulumi.Output[str]:
        """
        - (Required) Identifies the group that has access to the product and this stream configuration.
        """
        return pulumi.get(self, "group_id")

    @property
    @pulumi.getter(name="groupName")
    def group_name(self) -> pulumi.Output[str]:
        """
        The name of the user group for which the stream was created
        """
        return pulumi.get(self, "group_name")

    @property
    @pulumi.getter(name="httpsConnector")
    def https_connector(self) -> pulumi.Output[Optional['outputs.DatastreamHttpsConnector']]:
        """
        Specify details about the custom HTTPS endpoint you can use as a connector for a stream, including:
        """
        return pulumi.get(self, "https_connector")

    @property
    @pulumi.getter(name="modifiedBy")
    def modified_by(self) -> pulumi.Output[str]:
        """
        The username who modified the stream
        """
        return pulumi.get(self, "modified_by")

    @property
    @pulumi.getter(name="modifiedDate")
    def modified_date(self) -> pulumi.Output[str]:
        """
        The date and time when the stream was modified
        """
        return pulumi.get(self, "modified_date")

    @property
    @pulumi.getter(name="oracleConnector")
    def oracle_connector(self) -> pulumi.Output[Optional['outputs.DatastreamOracleConnector']]:
        """
        Specify details about the Oracle Cloud Storage connector in a stream. When validating this connector, DataStream uses the provided `access_key` and `secret_access_key` values and tries to save an `Akamai_access_verification_<timestamp>.txt` file in your Oracle Cloud Storage folder. You can only see this file if the validation process is successful, and you have access to the Oracle Cloud Storage bucket and folder that you’re trying to send logs to.
        """
        return pulumi.get(self, "oracle_connector")

    @property
    @pulumi.getter(name="papiJson")
    def papi_json(self) -> pulumi.Output[str]:
        """
        The configuration in JSON format that can be copy-pasted into PAPI configuration to enable datastream behavior
        """
        return pulumi.get(self, "papi_json")

    @property
    @pulumi.getter(name="productId")
    def product_id(self) -> pulumi.Output[str]:
        """
        The ID of the product for which the stream was created
        """
        return pulumi.get(self, "product_id")

    @property
    @pulumi.getter(name="productName")
    def product_name(self) -> pulumi.Output[str]:
        """
        The name of the product for which the stream was created
        """
        return pulumi.get(self, "product_name")

    @property
    @pulumi.getter(name="propertyIds")
    def property_ids(self) -> pulumi.Output[Sequence[str]]:
        """
        - (Required) Identifies the properties that you want to monitor in the stream. Note that a stream can only log data for active properties.
        """
        return pulumi.get(self, "property_ids")

    @property
    @pulumi.getter(name="s3Connector")
    def s3_connector(self) -> pulumi.Output[Optional['outputs.DatastreamS3Connector']]:
        """
        - (Optional) Specify details about the Amazon S3 connector in a stream. When validating this connector, DataStream uses the provided `access_key` and `secret_access_key` values and saves an `akamai_write_test_2147483647.txt` file in your Amazon S3 folder. You can only see this file if validation succeeds, and you have access to the Amazon S3 bucket and folder that you’re trying to send logs to. The argument includes these sub-arguments:
        """
        return pulumi.get(self, "s3_connector")

    @property
    @pulumi.getter(name="splunkConnector")
    def splunk_connector(self) -> pulumi.Output[Optional['outputs.DatastreamSplunkConnector']]:
        """
        Specify details about the Splunk connector in your stream. Note that currently DataStream supports only endpoint URLs ending with `collector/raw`. The argument includes these sub-arguments:
        """
        return pulumi.get(self, "splunk_connector")

    @property
    @pulumi.getter(name="streamName")
    def stream_name(self) -> pulumi.Output[str]:
        """
        - (Required) The name of the stream.
        """
        return pulumi.get(self, "stream_name")

    @property
    @pulumi.getter(name="streamType")
    def stream_type(self) -> pulumi.Output[str]:
        """
        - (Required) The type of stream that you want to create. Currently, `RAW_LOGS` is the only possible stream type.
        """
        return pulumi.get(self, "stream_type")

    @property
    @pulumi.getter(name="streamVersionId")
    def stream_version_id(self) -> pulumi.Output[int]:
        """
        Identifies the configuration version of the stream
        """
        return pulumi.get(self, "stream_version_id")

    @property
    @pulumi.getter(name="sumologicConnector")
    def sumologic_connector(self) -> pulumi.Output[Optional['outputs.DatastreamSumologicConnector']]:
        """
        Specify details about the Sumo Logic connector in a stream, including:
        """
        return pulumi.get(self, "sumologic_connector")

    @property
    @pulumi.getter(name="templateName")
    def template_name(self) -> pulumi.Output[str]:
        """
        - (Required) The name of the data set template available for the product that you want to use in the stream. Currently, `EDGE_LOGS` is the only data set template available.
        """
        return pulumi.get(self, "template_name")

